{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Feature extractor\n",
        "Since the bad organization of the dataset, in order to have a more organized code, we used this file to create 3 .csv files with the following features:\n",
        "* All the files are csv files where the columns are the elements of the exctracted (using the encoder part of the network) feature vector and the first column is the name of the related image;\n",
        "* All the image in the sets trully exists in one of the image folders;\n",
        "* Since no image for the test set exists we partitioned the train one.\n"
      ],
      "metadata": {
        "id": "K9dyqbpODm9x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b4bM7nc39Kft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import string\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from time import time\n",
        "import pandas as pd\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import load_img, img_to_array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Embedding, Dense, Activation, Flatten, Reshape, Dropout, Bidirectional, Add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In37HcfS9_l7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#use your path to download the dataset\n",
        "!unzip /content/drive/MyDrive/Natural\\ Language\\ Processing/projectDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv63jthNnDYo",
        "outputId": "8333faeb-c721-4b28-f5bf-c3ecea15dbde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ],
      "source": [
        "train_rad_ = pd.read_csv('/content/all_data/train/radiologytraindata.csv')\n",
        "test_rad = train_rad_[0:10000]\n",
        "train_rad = train_rad_[10000:].reset_index()\n",
        "val_rad = pd.read_csv('/content/all_data/validation/radiologyvaldata.csv')\n",
        "test_rad.drop(columns=['id'],inplace=True)\n",
        "train_rad.drop(columns=['id'],inplace=True)\n",
        "val_rad.drop(columns=['id'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JLJ4vPITkfIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fa261e-daf7-4a30-bb43-c01e7ba7a178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96112376/96112376 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Pretrained model for the featere vector extraction (encoder part)\n",
        "model = InceptionV3(weights='imagenet')\n",
        "model_new = Model(model.input, model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "37cPeu5dmnA_"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/all_data/train/radiology/images/'\n",
        "validation_path = '/content/all_data/validation/radiology/images/'\n",
        "test_path = '/content/all_data/train/radiology/images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FqjOnQ34lngZ"
      },
      "outputs": [],
      "source": [
        "#Each image is preprocessed and then feeded to the pretrained network\n",
        "def preprocess(image_path):\n",
        "    if  os.path.exists(image_path):\n",
        "      img=None\n",
        "      try:\n",
        "        img = load_img(image_path, target_size=(299, 299))\n",
        "      except:\n",
        "        print(\"image not recognized\")\n",
        "        return None\n",
        "    else:\n",
        "       return None\n",
        "    x = None\n",
        "    if img is not None:\n",
        "      x = img_to_array(img)\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "      x = preprocess_input(x)\n",
        "    return x\n",
        "\n",
        "def encode(image):\n",
        "    image = preprocess(image) \n",
        "    fea_vec = None\n",
        "    if image is not None:\n",
        "      fea_vec = model_new.predict(image, verbose=0) \n",
        "      fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\n",
        "    return fea_vec\n",
        "\n",
        "def get_features(path, dataframe):\n",
        "  encoding = {}\n",
        "  for i in range(len(dataframe)):\n",
        "    try:\n",
        "      img_name = dataframe['name'][i]\n",
        "      img = path + img_name\n",
        "      encoded_img = encode(img)\n",
        "      if encoded_img is not None:\n",
        "        encoding[img_name] = encoded_img\n",
        "    except:\n",
        "        print('err')\n",
        "  return encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSfE0fcpI3OV"
      },
      "outputs": [],
      "source": [
        "encoding_train = get_features(train_path, train_rad)\n",
        "pd.DataFrame(encoding_train.values()).to_csv(\"features_training.csv\")\n",
        "pd.DataFrame(encoding_train.keys()).to_csv(\"img_training.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WFROPi5bW1X9"
      },
      "outputs": [],
      "source": [
        "encoding_test = get_features(train_path, test_rad)\n",
        "pd.DataFrame(encoding_test.values()).to_csv(\"features_test.csv\")\n",
        "pd.DataFrame(encoding_test.keys()).to_csv(\"img_tes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aAH3s9CZJLXF"
      },
      "outputs": [],
      "source": [
        "encoding_val = get_features(validation_path, val_rad)\n",
        "pd.DataFrame(encoding_val.values()).to_csv(\"features_val.csv\")\n",
        "pd.DataFrame(encoding_val.keys()).to_csv(\"img_val.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}